# File: baseline_evaluation.py

from open_spiel.python.examples.bridge_wb5 import controller_factory
from absl import app
from absl import flags
import numpy as np
import pyspiel
from open_spiel.python.bots import bluechip_bridge
import time
FLAGS = flags.FLAGS
import jax.numpy as jnp
import pickle, os
import haiku as hk
import jax
import jax.numpy as jnp
import optax
from Algorithm.dummy_ai_forward import DummyNet
from open_spiel.python.Tongits.Algorithm.bridge_pg_trainer import policy_network_fn  # ç›´æŽ¥é‡ç”¨å®šç¾©

def load_rl_model(step, checkpoint_dir=os.path.join(os.path.dirname(os.path.abspath(__file__)),"checkpoints/bridge_pg" )):
    """è¼‰å…¥ RL è¨“ç·´å¥½çš„ Haiku æ¨¡åž‹åƒæ•¸."""
    # è¼‰å…¥ params
    with open(os.path.join(checkpoint_dir, f"params_{step}.pkl"), "rb") as f:
        params = pickle.load(f)

    # é‡å»º network (éœ€è¦çŸ¥é“ num_actions/obs_size)
    game = pyspiel.load_game("bridge(use_double_dummy_result=True)")
    num_actions = game.num_distinct_actions()
    obs_shape = game.observation_tensor_shape()
    obs_size = int(np.prod(obs_shape))

    net_fn = policy_network_fn(num_actions, hidden_units=[256, 256])
    policy_network = hk.without_apply_rng(hk.transform(net_fn))

    return policy_network, params


# åˆå§‹åŒ–
dummy_model = DummyNet()

flags.DEFINE_string("ai_model", "dummy", "é¸æ“‡ AI æ¨¡åž‹ (dummy, pg, rl2, random)")

def dummy_action(state):
    # å–å¾— observation (571 ç¶­)
    obs = np.array(state.observation_tensor(), dtype=np.float32)
    obs = jnp.expand_dims(obs, axis=0)  # (1, 571)

    # æ¨¡åž‹ forward
    logits = dummy_model.forward(obs)
    action = int(jnp.argmax(logits, axis=-1)[0])  # é¸ argmax å‹•ä½œ

    # ç¢ºä¿å‹•ä½œåˆæ³•
    legal_actions = state.legal_actions()
    if action in legal_actions:
        # print("argmax åˆæ³•ï¼Œé¸æ“‡è©²å‹•ä½œ")
        return action
    else:
        # print("argmax ä¸åˆæ³•ï¼Œéš¨æ©ŸæŒ‘ä¸€å€‹åˆæ³•å‹•ä½œ")
        return np.random.choice(legal_actions)

def ai_action_selector(state):
    model_name = FLAGS.ai_model.lower()
    
    if model_name == "dummy":
        return dummy_action(state)
    
    elif model_name == "random":
        return np.random.choice(state.legal_actions())
    
    elif model_name == "pg":
        # print("ä½¿ç”¨ RL æ¨¡åž‹ : policy gredient é¸å‹•ä½œ")
        if not hasattr(ai_action_selector, "rl_model"):
            # ç¬¬ä¸€æ¬¡è¼‰å…¥æ¨¡åž‹
            policy_network, params = load_rl_model(step=100000)  # ä½ è¦é¸æ“‡å°æ‡‰çš„ checkpoint
            ai_action_selector.rl_model = (policy_network, params)

        policy_network, params = ai_action_selector.rl_model

        # æº–å‚™ observation
        obs = np.array(state.observation_tensor(), dtype=np.float32)
        obs = jnp.array(obs)

        # å‰å‘æŽ¨è«–
        logits = policy_network.apply(params, obs)

        # éŽæ¿¾ä¸åˆæ³•å‹•ä½œ
        legal_actions_mask = jnp.array(state.legal_actions_mask())
        logits = jnp.where(legal_actions_mask, logits, -jnp.inf)

        # é¸ argmax å‹•ä½œ
        action = int(jnp.argmax(logits))

        if action in state.legal_actions():
            # print("argmax åˆæ³•ï¼Œé¸æ“‡è©²å‹•ä½œ")
            return action
        else:
            # print("argmax ä¸åˆæ³•ï¼Œéš¨æ©ŸæŒ‘ä¸€å€‹åˆæ³•å‹•ä½œ")
            return np.random.choice(state.legal_actions())

    
    elif model_name == "rl2":
        # TODO: é€™è£¡æ”¾ä½ çš„ RL æ¨¡åž‹2
        return np.random.choice(state.legal_actions())  # å…ˆä½”ä½
    
    else:
        raise ValueError(f"æœªçŸ¥çš„ ai_model: {FLAGS.ai_model}")

def _run_once(state, bots, net, params):
  """Plays bots with each other, returns terminal utility for each player."""
  for bot in bots:
    bot.restart()
  while not state.is_terminal():
    if state.is_chance_node():
      outcomes, probs = zip(*state.chance_outcomes())
      state.apply_action(np.random.choice(outcomes, p=probs))
    else:
      if FLAGS.sleep:
        time.sleep(FLAGS.sleep)  # wait for the human to see how it goes
        
      if state.current_player() % 2 == 1:# çŽ©å®¶ 1,3
        # Have simplest play for now
        action = state.legal_actions()[0]
        if action > 51:
          # TODO(ed2k) extend beyond just bidding
            action = ai_action_selector(state)
        state.apply_action(action)
        
      else: # WBridge5 æ©Ÿå™¨äºº (0,2)
        result = bots[state.current_player() // 2].step(state)
        state.apply_action(result)
  return state

def main(argv):
  if len(argv) > 1:
    raise app.UsageError("Too many command-line arguments.")
  game = pyspiel.load_game("bridge(use_double_dummy_result=false)")
  # net, params = load_model()
  net, params = None, None  # TODO: å…ˆä¸ä½¿ç”¨
  bots = [
      bluechip_bridge.BlueChipBridgeBot(game, 0, controller_factory),
      bluechip_bridge.BlueChipBridgeBot(game, 2, controller_factory)
  ]

  results = []

  for i_deal in range(FLAGS.num_deals):
    state =  _run_once(game.new_initial_state(), bots, net, params)
    print("Deal #{}; final state:\n{}".format(i_deal, state))
    print(f"  å®Œæˆå°å±€: {i_deal + 1}/{FLAGS.num_deals}", end='\r')

    results.append(state.returns())

  stats = np.array(results)
  # mean = np.mean(stats, axis=0)
  # stderr = np.std(stats, axis=0, ddof=1) / np.sqrt(FLAGS.num_deals)
  # print(u"Absolute score: {:+.1f}\u00b1{:.1f}".format(mean[0], stderr[0]))
  # print(u"Relative score: {:+.1f}\u00b1{:.1f}".format(mean[1], stderr[1]))
  output_report(stats)

def output_report(stats):
    opponent_name = FLAGS.ai_model  # ä¾‹å¦‚ dummy, pg, rl2, random

    # WBridge5 éšŠä¼: åŒ—å— (0, 2)
    ns_scores = stats[:, 0] + stats[:, 2] 
    # å°æ‰‹éšŠä¼: æ±è¥¿ (1, 3)
    ew_scores = stats[:, 1] + stats[:, 3] 

    # è¨ˆç®— WBridge5 éšŠç›¸å°æ–¼å°æ‰‹çš„å¹³å‡å¾—åˆ†å·®ç•°
    score_diffs = ns_scores - ew_scores
    
    mean_diff = np.mean(score_diffs)
    std_err_diff = np.std(score_diffs, ddof=1) / np.sqrt(FLAGS.num_deals)
    
    # å‹çŽ‡è¨ˆç®—
    ns_wins = np.sum(score_diffs > 0)
    ew_wins = np.sum(score_diffs < 0)
    draws = np.sum(score_diffs == 0)
    
    ns_win_rate = ns_wins / FLAGS.num_deals
    ew_win_rate = ew_wins / FLAGS.num_deals
    draw_rate = draws / FLAGS.num_deals

    report_str = []
    report_str.append("--- åŸºæº–æ¸¬è©¦æœ€çµ‚çµæžœ ---")
    report_str.append(f"AI å°æ‰‹: {opponent_name}")
    report_str.append(f"å°å±€ç¸½æ•¸: {FLAGS.num_deals}")
    report_str.append(f"WBridge5 (NS) å¹³å‡å¾—åˆ†: {np.mean(ns_scores):.2f}")
    report_str.append(f"{opponent_name} (EW) å¹³å‡å¾—åˆ†: {np.mean(ew_scores):.2f}")
    report_str.append("å¹³å‡å¾—åˆ†å·®ç•° (WBridge5 - {0}): {1:+.2f} Â± {2:.2f}".format(
        opponent_name, mean_diff, std_err_diff))
    report_str.append(f"WBridge5 (NS) å‹çŽ‡: {ns_win_rate:.2%}")
    report_str.append(f"{opponent_name} (EW) å‹çŽ‡: {ew_win_rate:.2%}")
    report_str.append(f"å¹³å±€çŽ‡: {draw_rate:.2%}")

    report_text = "\n".join(report_str)

    # å°åˆ°çµ‚ç«¯
    print("\n" + report_text)

    # å­˜æª”åˆ° baseline_evaluation_report_<ai_model>.txt
    out_name = f"baseline_evaluation_report_{opponent_name}.txt"
    out_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), out_name)
    with open(out_path, "w", encoding="utf-8") as f:
        f.write(report_text)
    print(f"\nðŸ“‚ å ±å‘Šå·²è¼¸å‡ºåˆ°: {out_path}")

if __name__ == "__main__":
  app.run(main)